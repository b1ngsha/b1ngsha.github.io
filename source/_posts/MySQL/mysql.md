---
title: 万字长文总结MySQL相关八股
date: 2024-03-29 22:24:04
tags: 
- MySQL
- 八股
categories: MySQL
---
> 最近把小林coding图解MySQL的主要内容梳理了一下，根据自己的理解整理出了这篇文章

<!--more-->

## 基础

### 执行一条select语句，期间发生了什么？

1. 连接器。通过TCP三次握手与MySQL服务器建立连接。如果MySQL服务正常运行，完成TCP连接的建立后，连接器就会验证你的用户名和密码，通过后获取用户权限，然后保存起来，后续该用户在此连接里的任何操作，都会基于连接开始时读到的权限进行权限逻辑的判断
   * 在MySQL中，也像HTTP一样有长连接和短连接的概念。使用长连接可能会导致占用的内存增多，因为MySQL在执行查询的过程中临时使用内存来管理连接对象，而这些连接对象资源只有在连接断开时才会释放，因此如果连接对象过多，就会导致MySQL服务占用太多的内存，有可能会被系统强制kill掉，就会发生MySQL服务异常重启的现象
2. 查询缓存。在查询缓存中查找缓存数据，看看之前有没有执行过这条命令，如果有对应的K-V键值对（select语句-执行结果），则直接返回查询结果。但是这个查询缓存在MySQL8.0版本被移除了，因为对于更新频繁的表，查询缓存命中率是很低的。有可能刚在缓存中缓存了一个很大的结果集，表发生更新后这个结果集就从缓存中被删掉了，相当于白存
3. 解析器。
   1. 词法解析。将输入的语句中的关键字识别出来
   2. 语法解析。判断输入的语句是否满足语法，如果没问题就生成语法树
4. 执行器。
   1. prepare。检查查询语句中的表和字段是否存在；把`select *`中的`*`扩展为所有字段
   2. optimize。确定该语句的执行方案（使用什么索引）
   3. execute。执行SQL语句



### 索引下推

假设有下面这条查询语句：

```sql
SELECT * FROM t_user WHERE age > 20 AND reward = 100000;
```

假设有联合索引 (age, reward)，此时age字段能用到索引，但是reward无法用到索引

在不使用索引下推时：

* Server层调用存储引擎的接口定位到第一条 age > 20 的记录
* 存储引擎根据B+树定位到这条记录后，获取主键值，**进行回表操作**，将完整的记录返回给Server层
* Server层再判断这条记录的reward是否等于100000，如果是的话则直接返回给客户端，否则跳过
* 接着，Server层继续像存储引擎索要下一条记录，存储引擎定位到这条记录后，获取主键值，回表，返回记录，反复这个过程



使用索引下推后：

* Server层首先调用存储引擎的接口定位到第一条 age > 20 的记录
* 定位到之后，先不执行回表操作，而是先判断一下 reward = 100000 是否成立，如果不成立，则**直接跳过该索引**，如果成立，则**执行回表操作**，将记录返回给Server层
* Server层再判断其他条件（本例子中的查询没有其他条件）是否成立，如果成立则将其发送给客户端，否则跳过这条记录，然后向存储引擎索要下一条记录，反复这个过程

也就是说，**可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**



在执行计划的 `Extra` 部分如果显示了 `Using index condition`，就说明使用了索引下推



### MySQL的一行数据是怎么存储的？

#### MySQL的数据存放在哪个文件？

当我们每创建一个数据库时，都会在`mysql/data`这个路径下创建一个以这个数据库名命名的目录，保存这个数据库中的表结构和表数据的文件都会存放在这个目录里

![image-20240328111114436](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328111114436.png)



进入其中一个目录，看看里面有什么文件？

在小林Coding的文章中，目录中包含了三个文件：

* `db.opt`：用来存储当前数据库的默认字符集和字符校验规则
* `xxx.frm`：xxx的表结构会保存在这个文件
* `xxx.ibd`：xxx的表数据会保存在这个文件
  * 表数据既可以存储在**共享表空间文件**（ibdata1）里，也可以存放在**独占表空间文件**（xxx.ibd）
  * 这个行为是由参数`innodb_file_per_table`来控制的，若设置为1，则会将存储的数据、索引等信息单独存储在一个独占表空间
    * 从MySQL5.6.6版本开始，默认值为1



而我在自己的目录下却**并没有发现`.frm`文件的存在**：

![image-20240328111619920](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328111619920.png)



查阅官方文档发现，从MySQL8.0开始，`.frm`文件已经被移除了

![image-20240328112925419](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328112925419.png)



**之前在`.frm`中的信息现在被存储在序列化字典（serialized dictionary information，SDI）中**。在InnoDB中，这个SDI数据被保存在.ibd文件中，而对于其他的存储引擎则是被存储在`.sdi`文件中。SDI数据是以JSON格式组织的

![image-20240328112947089](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328112947089.png)



可以使用`ibd2sdi`工具来提取`.ibd`文件中的元数据（也就是表结构）：

![image-20240328113136979](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328113136979.png)

![image-20240328113149131](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328113149131.png)



### 表空间文件的结构是怎么样的？

**表空间由段（segment）、区（extent）、页（page）、行（row）组成**，InnoDB存储引擎的逻辑存储结构大致如下图：

![image-20240328165826947](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328165826947.png)

1. 行（row）

   数据库表中的记录都是按行存放的，每行记录有根据不同的行格式，有不同的存储结构

   这里的行指的就是行记录

   

2. 页（page）

   记录是按行存储的，但是**数据库是按页为单位来进行读写的**。**默认每个页的大小为16KB**

   页的类型有很多，常见的有数据页、undo日志页、溢出页等等。**表中的行记录是用数据页来管理的**

   

3. 区（extent）

   在B+树中，每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，也就是每个节点对应的都是一个数据页，那么链表中**相邻的两个页之间的物理位置不是连续的**，磁盘查询时就可能会产生大量的**随机I/O**，而随机I/O的效率是很低的

   解决方案：当表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是**按照区为单位分配**。每个区的大小为1MB，对于16KB的页来说，连续的64个页会被划为一个区，这样就使得链表中相邻的页都放在一个区中，使得他们的物理位置也相邻，就能使用顺序I/O了

   

4. 段（segment）

   表空间是由各个段组成的，段一般分为数据段、索引段和回滚段等

   - 索引段：存放B+树的非叶子节点的区的集合
   - 数据段：存放B+树的叶子节点的区的集合
   - 回滚段：存放的是回滚数据的区的集合



#### Compact行格式长什么样？

InnoDB提供了4种行格式，分别是Redundant、Compact、Dynamic和Compressed行格式

由于默认采用Compact这种行格式，重点了解这种即可

![image-20240328171659834](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328171659834.png)

##### 记录的额外信息

记录的额外信息包含3个部分：变长字段长度列表、NULL值列表、记录头信息，以下逐个进行分析：

1. 变长字段长度列表

   在字段定义时，经常使用`varchar`这种变长的数据类型，所以，在存储数据的时候，也要把数据占用的大小存起来，存到变长字段长度列表里面，读取数据的时候才能根据这个变长字段长度列表去读取对应长度的数据

   

   假设有这样一张表：

   ```sql
   CREATE TABLE `t_user` (
     `id` int(11) NOT NULL,
     `name` VARCHAR(20) DEFAULT NULL,
     `phone` VARCHAR(20) DEFAULT NULL,
     `age` int(11) DEFAULT NULL,
     PRIMARY KEY (`id`) USING BTREE
   ) ENGINE = InnoDB DEFAULT CHARACTER SET = ascii ROW_FORMAT = COMPACT;
   ```

   表中有三条记录：

   ![image-20240328171929758](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328171929758.png)

   对于第一条记录来说：

   ![image-20240328172005963](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328172005963.png)

   由于`name`的列值为a，占用的字节数为1字节，十六进制表示为0x01，因此在这里显示为01，同理，`phone`表示为03

   

   可以注意到，在变长字段长度列表中真实数据占用的字节数都是**逆序存放**的，那么为什么要这样设计呢？

   主要是因为在记录头信息中，有一个指向下一条记录的指针，指向的是下一条记录的记录头信息和真实数据之间的位置：

   ![image-20240328172429500](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328172429500.png)

   这样的好处是向左就可以读到头信息，向右就可以读到真实数据

   那么之所以变长字段长度列表要逆序存放，就是因为向左右两边读取的时候，可以**使得变长字段和它的长度同时在一个CPU Cache Line中，以提高Cache的命中率**

   

   **注意，当数据表中没有变长字段时，就不会出现变长字段长度列表**

   

2. null值列表

   如果存在允许NULL值的列，**则每个列对应一个二进制位**（1为NULL，0不为NULL），二进制位按照列的顺序**逆序排列**（这里使用逆序排列的思路和变长字段长度列表相同）

   另外，如果使用的二进制位个数不足整数个字节，则需要补0

   以上表的第二条记录为例：

   ![image-20240328173243501](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240328173243501.png)

   

**注意，NULL值列表也不是必须的，如果所有字段都被定义为NOT NULL，也就不会有NULL值列表了**



每条记录的行格式如下：

![image-20240218231037494](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240218231037494.png)



## 索引

### 前缀索引

* 当字段类型为字符串（text、varchar等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO，影响查询效率。此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。

  ```sql
  CREATE INDEX idx_xxxx ON table_name(column(n));
  ```

* 前缀长度

  可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表记录总数的比值，索引选择性越高则查询效率越高，唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的

  ```sql
  SELECT COUNT(DISTINCT email) / COUNT(*) FROM tb_user;
  SELECT COUNT(DISTINCT substring(email, 1, 5)) / COUNT(*) FROM tb_user;
  ```

* 前缀索引的结构：

  ![image-20231202004055287](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20231202004055287.png)

* 查询流程：先从前缀索引中找到符合目标字符串前缀的索引节点，获取主键值进行回表操作，回表得到行记录后再判断字段值是否符合查询条件，如果符合则返回给Server层，如果不符合则向下继续查找



### 联合索引范围查询

假设有联合索引(a, b)：

```sql
SELECT * FROM t_table WHERE a > 1 AND b = 2;
```

由于联合索引是先按照a字段的值排序的，所以符合a > 1条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合a > 1条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合a > 1条件的位置。所以a字段可以在联合索引中进行索引查询

而在a > 1这个范围中，**b的字段是无序的**，所以b并不能走索引



```sql
SELECT * FROM t_table WHERE a >= 1 AND b = 2;
```

在这个例子中，b是可以走索引的，因为**在a = 1这个边界，b字段的值是有序的**，因此可以利用索引减少搜索范围

> 之前在这里有一个想了很久才想通的问题：既然在这个边界上有序就可以走索引，那我在区间内的每个a其实都是局部有序的，那为什么不能走索引呢？
>
> 后来思考觉得是因为在区间上有序的话，就可以利用索引减少搜索范围，也就是说这里可以直接从a = 1, b = 2这个节点开始向右搜索，而对每个点虽然都是局部有序的，但是还是要对于每个a > 1的点都判断b是否等于2，其实没有利用到索引来减少搜索范围，因此是不走索引的



```sql
SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2;
```

与第二条SQL相同，可以**在边界上减少查询范围**，所以都可以走索引



```sql
SELECT * FROM t_user WHERE name like 'j%' and age = 22;
```

同样，都可以走索引，因为**在name = j这个边界上可以减少搜索范围**



### 利用联合索引进行排序

针对下面的这条SQL，你会怎么通过索引来提高查询效率呢？

```sql
SELECT * FROM ORDER WHERE status = 1 ORDER BY create_time ASC
```

给`status`和`create_time`两列建立一个联合索引，就可以避免文件排序

因为在查询时，如果只用到`status`的索引，但是这条语句还要对`create_time`排序，这时就要用文件排序

所以，要利用索引的有序性，在`status`和`create_time`列建立联合索引，这样根据`status`筛选后的数据就是按照`create_time`排好序的，避免在文件排序，提高了查询效率



### 什么时候需要/不需要创建索引？

索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：

- 需要占用物理空间，数量越大，占用空间越大
- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大
- 会降低表的增删改的效率，因为每次增删改索引，B+树为了维护索引有序性，都需要进行动态维护



什么时候适用索引？

- 字段有**唯一性**限制的，比如商品编码
- 经常用于`WHERE`查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引
- 经常用于`GROUP BY`和`ORDER BY`的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在B+Tree中的记录都是排序好的



什么时候不需要创建索引？

- `WHERE`条件，`GROUP BY`，`ORDER BY`里用不到的字段，索引的价值是快速定位，如果起不到定位作用的字段通常是不需要创建索引的，因为索引是会占用物理空间的
- 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为MySQL还有一个查询优化器，**查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描**
- **表数据太少**的时候，不需要创建索引
- **经常更新的字段**不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的

### InnoDB是如何存储数据的？

B+树中的一个节点对应着一个数据页。**数据页中的记录按主键顺序组成单向链表**。数据页中有一个**页目录**，起到记录的索引作用

![image-20240218231604646](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240218231604646.png)

页目录的创建过程：

1. 将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录
2. 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为`n_owned`字段（上图中粉红色字段）
3. 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），**每个槽相当于指针指向了不同组的最后一个记录**

从图可以看到，**页目录就是由多个槽组成的，槽相当于分组记录的索引**。然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表



### B+树是如何进行查询的？

上面描述的是确定了记录在哪个数据页后如何从数据页中搜索出数据，这里描述的是如何找到记录所在的数据页

InnoDB里的B+树中的**每个节点都是一个数据页**，结构示意图如下：

![image-20240218231819971](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240218231819971.png)

通过上图，我们看出B+树的特点：

- 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节点）仅用来存放目录项作为索引
- 非叶子节点分为不同层次，通过分层来降低每一层的搜索量
- 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询

> 理解：这里的非叶子节点中存放的是索引对应的数据页，从每一层获取到要读取的数据页后从磁盘中读取这个数据页，再找下一个需要读取的是哪个数据页，再从磁盘中进行读取。直到找到叶子节点的数据页，根据页目录找到对应的组，然后在组内遍历找到目标记录



### 为什么使用B+树作为索引的数据结构？

因为MySQL的索引和记录都存储在硬盘，硬盘的存取速度是很慢的，因此我们在查询数据的时候，应该**尽可能地减少磁盘IO的次数**。并且由于在MySQL中支持范围查询，因此索引的数据结构也需要**满足范围查询**

在选用索引的数据结构时，在尽可能减少磁盘IO的同时也要保证数据结构本身较高的查询效率

* 首先可以想到如果将索引按序排列的话，使用**数组+二分查找**的方式可以达到**O(logn)**的查询效率。但是使用数组的弊端是在插入数据时需要对元素进行移动，并且每次查找都需要计算中间的位置
* 为了解决这些弊端，可以采用**二叉查找树**。这样就不再需要计算中间位置，只需要将查找的数据与节点的数据进行比较。并且，因为二叉查找树不需要连续排列，因此在插入的时候，新节点可以放在任意位置，不会出现大规模元素移动的操作。但是，二叉查找树**存在退化成链表的可能性**，导致**查询效率退化为O(n)**，磁盘IO次数增多，性能严重下降
* 进而可以想到使用自平衡二叉树，它能够在天然地适配二分查找的同时，在插入节点的时候也能维持树的平衡结构，不至于像二分查找树一样退化为链表。但是二叉树的弊端是在当数据量变大时，**树的高度很容易变得很高**，也就意味着更多的磁盘IO次数
* 为了解决这个问题，只要将树的分叉数增加即可，也就是B树和B+树。而将B树与B+树进行比较，B树有以下几点不足：
  1. B树的非叶子节点也存放了行数据，而B+树的非叶子节点中**不存放行数据**，因此B+树的非叶子节点中可以存放更多的索引，也就导致了树的高度更矮，使得磁盘IO次数更少
  2. B树如果要进行范围查询的话需要对树进行**多次遍历**来完成，而B+树在叶子节点之间设计了**双向链表**进行连接，很好地适配了范围查询的场景
  3. B+树**存在大量的冗余节点**（非叶子节点），使得B+树在删除、插入的效率都比B树更高，不会像B树那样发生复杂的树结构的变化



> 扩展一下，在MyISAM存储引擎中，如果是聚簇索引，那么B+树索引的叶子节点保存的是数据的物理地址



### 索引失效有哪些？

* 左模糊匹配（`like %x`）或左右模糊匹配（`like %x%`）
* 对索引使用函数
* 对索引进行表达式运算
* 对索引进行隐式类型转换（MySQL会自动将字符串转成数字）
* 联合索引非最左匹配
* WHERE子句中的OR



### 使用左模糊匹配一定会使索引失效吗？

* 使用左模糊匹配（`like "%xx"`）并不一定会走全表扫描，关键还是看数据表中的字段

* 如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type=all），而是**走全扫描二级索引树**(type=index)

* 假设有表t，t中有字段id和name，为name建立了二级索引，那么在执行`SELECT * FROM t WHERE name like %x`时，相当于`SELECT id, name FROM t where name like %x`，此时可以直接通过覆盖索引的方式在二级索引的叶子节点中找到id和name的值，因此编译器**会进行全扫描二级索引树**的操作

  > 为什么选择扫描二级索引树，而不是聚簇索引树呢？
  >
  > 因为聚簇索引中记录的东西更多，比如主键值、事务id、MVCC回滚指针等，而二级索引树记录的东西很少，只有索引列和主键值，并且这里的`SELECT *`不用执行回表的操作，所以优化器认为直接遍历二级索引树成本更小，因此扫描二级索引树

  而如果表中含有非索引字段时，`SELECT *`就需要进行回表操作，优化器认为回表操作的成本太高了，干脆直接进行全表扫描

* 再说一个相似的，我们都知道联合索引要遵循最左匹配才能走索引，但是如果数据库表中的字段都是索引的话，即使查询过程中，没有遵循最左匹配原则，也是走全扫描二级索引树(type=index)



### COUNT()解析

首先要明确，该函数作用是**统计符合查询条件的记录中，函数指定的参数不为NULL的记录有多少个**

#### COUNT(主键)的执行过程

* 在通过`count`函数统计有多少个记录时，MySQL的server层会维护一个名叫`count`的变量

* server层会循环向InnoDB读取一条记录，如果`count`函数指定的参数不为`NULL`，那么就会将变量`count`加1，直到符合查询的全部记录被读完，就退出循环。最后将`count`变量的值发送给客户端
* 如果表里只有主键索引，没有二级索引时，那么，InnoDB循环遍历聚簇索引，将读取到的记录返回给server层，然后读取记录中的id值，判断id值是否为NULL，如果不为 NULL，就将count变量加1
* **如果表里有二级索引时，InnoDB 循环遍历的对象就不是聚簇索引，而是二级索引**
  * 这是因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的I/O成本比遍历聚簇索引的I/O成本小，因此优化器**优先选择的是二级索引**



#### COUNT(1)的执行过程

* 循环遍历聚簇索引（主键索引），将读取到的记录返回给server层，**但是不会读取记录中的任何字段的值**，因为count函数的参数是1，不是字段，所以不需要读取记录中的字段值。参数1很明显并不是NULL，因此server层每从InnoDB读取到一条记录，就将count变量加1



#### COUNT(*)的执行过程

* **`count(\*)`其实等于`count(0)`**，也就是说，当你使用`count(*)`时，MySQL 会将\*参数转化为参数0来处理

* 而且MySQL 会对`count(*)`和`count(1)`有个优化，如果有多个二级索引的时候，优化器会使用key_len最小的二级索引进行扫描



#### 为什么要通过遍历的方式来计数？

* InnoDB存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的，所以无法像MyISAM一样，只维护一个 `row_count`变量。



## 慢查询如何优化？

可以参考这篇文章：[字节面试官：一条sql执行慢的原因？如何优化？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/409390845)

索引优化（前缀索引优化，覆盖索引优化，主键自增，索引最好设置为not null）



## 事务

### 事务有哪些特性？

* **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成
* **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态
* **隔离性（Isolation）**：防止多个事务并发执行时由于交叉执行而导致数据的不一致
* **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失



对于InnoDB引擎来说：

- 持久性是通过redo log（重做日志）来保证的
- 原子性是通过undo log（回滚日志）来保证的
- 隔离性是通过MVCC（多版本并发控制）或锁机制来保证的
- 一致性则是通过持久性+原子性+隔离性来保证



### 并发事务会出现什么问题？

* 脏读
* 不可重复读
* 幻读



> 如何区分幻读和脏读？
>
> 脏读更侧重于**记录内容**是否一致，而幻读则是更侧重于**记录数量**是否一致



### 事务的隔离级别

**MySQL InnoDB引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了）**，解决的方案有两种：

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题
- 针对**当前读**（select ... for update 等语句），是**通过next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上next-key lock，如果有其他事务在next-key lock锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题



- 对于读未提交隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了
- 对于串行化隔离级别的事务来说，通过加读写锁的方式来避免并行访问
- 对于读提交和可重复读隔离级别的事务来说，它们是通过**Read View来实现的，它们的区别在于创建Read View的时机不同。读提交隔离级别是在每个语句执行前都会重新生成一个Read View，而可重复读隔离级别是启动事务时生成一个Read View，然后整个事务期间都在用这个Read View**



### Read View是什么？

Read View由以下四个字段组成：

![image-20240329160914979](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240329160914979.png)



每条记录中都包含两个隐藏列：

![image-20240329161048410](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240329161048410.png)

- `trx_id`，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务id记录在`trx_id`隐藏列里**
- `roll_pointer`，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到undo日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录



因此，对于每条记录，就可以根据它的`trx_id`来判断是否对当前的Read View可见：

- 如果记录的`trx_id`值小于Read View中的`min_trx_id`值，表示这个版本的记录是在创建Read View**前**已经提交的事务生成的，所以该版本的记录对当前Read View**可见**
- 如果记录的`trx_id`值大于等于Read View 中的`max_trx_id`值，表示这个版本的记录是在创建Read View**后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**
- 如果记录的`trx_id`值在Read View的`min_trx_id`和`max_trx_id`之间，需要判断`trx_id`是否在`m_ids`列表中：
  - 如果记录的`trx_id`**在**`m_ids`列表中，表示**生成该版本记录的活跃事务依然活跃着**，所以该版本的记录对当前事务**不可见**
  - 如果记录的`trx_id`**不在**`m_ids`列表中，表示**生成该版本记录的活跃事务已经被提交**，所以该版本的记录对当前事务**可见**



### RR隔离级别完全解决幻读了吗？

没有完全解决



来看两个场景：

![image-20240329162351331](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240329162351331.png)

可以看到，事务A在第一次快照读没有读到id = 5的数据下，却去更新了数据，导致id = 5这行数据的`trx_id`变成了事务A的id，从而的场景下出现了幻读现象。这种场景虽然非常迷惑，但是确实会产生幻读现象



再来看第二个场景：

- T1时刻：事务A先执行快照读语句：`select * from t_test where id > 100`得到了3条记录
- T2时刻：事务B往插入一个id= 200的记录并提交
- T3时刻：事务A再执行当前读语句：`select * from t_test where id > 100 for update`就会得到 4 条记录，此时也发生了幻读现象

这种场景比较正常，当前读是会读取数据库中的最新数据的，因此也会产幻读现象



## 锁

### 全局锁

锁全库，一般是全库逻辑备份的时候用的

缺点：会造成业务停滞

解决方案：在RR级别下，在备份前先开启事务，就会先创建ReadView，根据这个ReadView来备份。具体做法为：在使用`mysqldump`备份时加上`-single-transaction`参数



### 表级锁

#### 元数据锁

**针对的是元数据（也就是表结构）**

我们不需要显示的使用元数据锁（MDL），因为当我们对数据库表进行操作时，会自动给这个表加上：

- 对一张表进行CRUD操作时，加的是MDL读锁
- 对一张表做结构变更操作的时候，加的是MDL写锁

在事务提交的时候会被释放



#### 意向锁

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。



**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（\*lock tables ... read\*）和独占表锁（\*lock tables ... write\*）发生冲突**



如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。



所以，**意向锁的目的是为了快速判断表里是否有记录被加锁**。



#### AUTO-INC锁

* 不是在一个事务提交之后释放，而是在执行完插入语句之后就会立即释放
* 在插入数据时，会加一个**表级别**的AUTO-INC锁，然后为被AUTO_INCREMENT修饰的字段赋值递增的值，等插入语句执行完成后，才会把AUTO-INC锁释放掉
* 一个事务在持有AUTO-INC锁的时候，其他事务的插入语句会被阻塞，以保证AUTO_INCREMENT的值是连续递增的
* MySQL提供了一种轻量级的锁来实现自增。在插入数据的时候，会为被AUTO_INCREMENT修饰的字段加上轻量级锁，然后给该字段赋值，赋值完就释放了，不用等到插入语句执行完成
* 具体选用哪个锁，可以通过系统变量`innodb_autoinc_lock_mode`来控制



### 行级锁

InnoDB 引擎是支持行级锁的，而**MyISAM引擎并不支持行级锁**



#### 记录锁

Record Lock称为记录锁，锁住的是一条记录



#### 间隙锁

Gap Lock称为间隙锁，只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象

间隙锁虽然存在X型间隙锁和S型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的**



#### 临键锁

Next-Key Lock称为临键锁，是Record Lock + Gap Lock的组合，锁定一个范围，并且锁定记录本身

**next-key lock是包含间隙锁+记录锁的，如果一个事务获取了X型的 next-key lock，那么另外一个事务在获取相同范围的X型的next-key lock时，是会被阻塞的**



#### 插入意向锁

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock也包含间隙锁）

如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态



### MySQL是怎么加行级锁的？

**在读已提交隔离级别下，行级锁的种类只有记录锁**

在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁。**加锁的对象是索引，加锁的基本单位是next-key lock**



#### 唯一索引等值查询

- 当查询的记录是**存在**的，在索引树上定位到这一条记录后，将该记录的索引中的next-key lock会**退化成记录锁**
- 当查询的记录是**不存在**的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的next-key lock会**退化成间隙锁**



* 对如下的SQL：`SELECT * FROM user WHERE id = 2 FOR UPDATE;`假设表中不存在id=2的数据，此时会在(1, 5)加上间隙锁
* 加锁的目的是为了解决幻读现象，因此将(1, 5)这个区间锁住就可以防止其他事务插入id=2的数据
* 如果其他记录插入id=1或id=5的记录的话，并不会发生阻塞，而是报主键冲突的错误
* 为什么会从next-key lock退化成间隙锁？
  * 如果是next-key lock，则会锁住(1, 5]这个区间的记录，但是我们并不需要对id=5这条记录上锁，只需要前后多次查询id=2的结果相同就可以了，没必要加next-key lock
  * 为什么不直接对id=2加记录锁？因为锁是加在索引上的，索引树中不存在id=2这条记录，自然无法上锁



#### 唯一索引范围查询

* 大于/大于等于

  ![image-20240222123902088](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222123902088.png)

  ![image-20240222123933256](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222123933256.png)

* 小于/小于等于

  ![image-20240222124007439](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222124007439.png)

  ![image-20240222124103693](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222124103693.png)

  ![image-20240222124028972](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222124028972.png)



#### 非唯一索引等值查询

* 当查询的记录不存在（age=25）时：

  ![image-20240222122244571](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222122244571.png)

* 当查询的记录存在（age=22）时：

  ![image-20240222122334288](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222122334288.png)

  * 为什么要在age=22的左右两个区间都加锁？

    * 因为加锁的单位是临键锁，所以对age = 22加锁的时候，首先会锁住(21, 22]这个区间

      > 为什么不像唯一索引那样，等值查询可以退化为记录锁？
      >
      > 因为 age 字段是非唯一索引，不具有唯一性，所以如果只加记录锁（记录锁无法防止插入，只能防止删除或者修改），就会导致其他事务插入一条age = 22的记录，这样前后两次查询的结果集就不相同了，出现了幻读现象。

    * 而对于(22, 39)这个间隙锁，是为了防止插入age = 22, id > 10的数据

  * 为什么要加主键索引？

    > 理解：防止其他事务通过主键索引删除id = 10，也就是age = 22这条记录，出现幻读现象



#### 非唯一索引范围查询

![image-20240222124201373](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240222124201373.png)



#### 没有加索引的查询

**如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加next-key锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞**

不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加next-key锁，这样就相当于锁住了全表



### update没加索引会锁全表？

**关键看这条语句在执行过程中，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了**

> update没走索引会加表锁的说法是不对的，这时是对全表扫描，也就是对表里的索引项都加锁，相当于锁了整张表，而不是直接加表锁



### 如何避免死锁？

* 死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立
* **设置事务等待锁的超时时间**
* **开启主动死锁检测**



## 日志

对于undo log、redo log、binlog的解析，建议直接看小林coding的原文，写得非常好，全篇无废话：

[MySQL 日志：undo log、redo log、binlog 有什么用？ | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/mysql/log/how_update.html#为什么需要-undo-log)



### 更新一条记录的流程

`UPDATE t_user SET name = 'xiaolin' WHERE id = 1;`

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
   - 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
   - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
   - 如果一样的话就不进行后续更新流程；
   - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。
4. InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 **WAL 技术**，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。
5. 至此，一条记录更新完了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。
7. 事务提交，这里就涉及到两阶段提交的内容了



### 两阶段提交

* 事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这是两个独立的逻辑，可能出现半成功的状态，就造成两份日志之间的逻辑不一致

  * 如果在将 redolog 刷盘之后，MySQL突然宕机了，而 binlog 还没有刷盘，这时主从复制时从库就丢失了数据，造成主从库的值不一致
  * 如果在将 binlog 刷盘之后，MySQL突然宕机了，而 redolog 还没有写入，这时恢复之后无法恢复数据，而 binlog 被复制到了从库，从库执行了这条更新语句，造成了主从库值的不一致

* 两阶段提交是把单个事务的提交拆分成了两个阶段，分别是 [准备(prepare)阶段] 和 [提交[commit]阶段]，每个阶段都由协调者和参与者共同完成

* MySQL使用了**内部XA事务**来保证 redolog 和 binlog 的一致性，客户端在执行事务提交时，MySQL内部会开启一个XA事务，分两阶段来完成XA事务的提交

  ![image-20240314113750351](https://b1ngsha-blog.oss-cn-beijing.aliyuncs.com/image-20240314113750351.png)

  * 可以看出事务的提交过程有两个阶段，就是**将 redolog 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入 binlog**
  * prepare阶段：将 XID（内部事务的ID）写入 redolog，然后将 redolog 对应的事务状态设置为 prepare，然后将 redolog 刷盘
  * commit阶段：将 XID 写入到 binlog，然后将 binlog 刷盘，然后调用引擎的提交事务接口，将 redolog 状态设置为 commit，并将这个状态 write 到 page cache 中

* 异常重启：

  * 当MySQL重启后会按顺序去扫描 redolog 文件，碰到处于 prepare 状态的 redolog，就拿着 redolog 中的 XID 去 binlog 查看是否存在此 XID：
    * 如果没有，说明 redolog 已完成刷盘，但是 binlog 还没有刷盘，回滚事务
    * 如果有，说明 redolog 和 binlog 都已经完成了刷盘，提交事务
  * 对于处于 prepare 阶段的 redolog，既可以提交事务，也可以回滚事务，这**取决于是否能在 binlog 中查找到与 redolog 相同的 XID**，如果有就提交，如果没有就回滚
  * 两阶段提交是以 binlog 写成功为事务提交成功的标识



## 内存

关于buffer pool中的空闲页的管理、脏页的管理、缓存命中率如何提高等问题都可以查看小林coding的文章，非常全面且详细：[揭开 Buffer Pool 的面纱 | 小林coding (xiaolincoding.com)](https://xiaolincoding.com/mysql/buffer_pool/buffer_pool.html#为什么要有-buffer-pool)